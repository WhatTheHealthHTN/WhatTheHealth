{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mindf\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from fastai.vision.all import *\n",
    "from ENSEMBLE_SCORING_ALGORITHM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize all Gradient Boosted Trees\n",
    "intialize_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Generator\n",
    "from GENERATOR_HEALTHCARE_MODEL import LeverGenerator\n",
    "\n",
    "#Generator model\n",
    "generator_model = LeverGenerator(1200)\n",
    "#Configure loss function\n",
    "loss_func = nn.MSELoss()\n",
    "#Configure Optimizer\n",
    "optimizer = torch.optim.Adam(generator_model.parameters(), lr = 0.01)\n",
    "\n",
    "#Training script for PyTorch (training and validation loops)\n",
    "def train_model(epochs, generator):\n",
    "    train_accuracies = []\n",
    "    train_losses = []\n",
    "    valid_accuracies = []\n",
    "    valid_losses = []\n",
    "    #Training Loop\n",
    "    iteration_loop(training = True, epochs = epochs, generator = generator, losses = train_losses, accuracies = train_accuracies)\n",
    "    #Validation Loop\n",
    "    iteration_loop(training = False, epochs = epochs, generator = generator, losses = valid_losses, accuracies = valid_accuracies)\n",
    "    return train_accuracies, train_losses\n",
    "\n",
    "def iteration_loop(training, epochs, generator, losses, accuracies):\n",
    "    epoch_losses = []\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(epochs): \n",
    "        #Set gradients to zero\n",
    "        generator.zero_grad()\n",
    "        inputs = torch.rand((1, 1200))\n",
    "        output = generator(inputs)\n",
    "        #Air quality metrics\n",
    "        aq_metrics = output[:13]\n",
    "        exercise_metrics = output[14:16]\n",
    "        #Blood report metrics\n",
    "        blood_report_metrics = output[17:31]\n",
    "        #Nutrition metrics\n",
    "        nutrition_metrics = output[32:37]\n",
    "        #Sleep metrics\n",
    "        sleep_metrics = output[37:40]\n",
    "        METRICS = {'pollution_gradient_tree' : aq_metrics, 'exercise': exercise_metrics,\n",
    "                   'nutrition_gradient_tree': nutrition_metrics, 'sleep_gradient_tree': sleep_metrics, \n",
    "                   'blood_gradient_tree': blood_report_metrics}\n",
    "        avg_score = get_avg_model_score(METRICS)\n",
    "        loss = 1 - avg_score\n",
    "        if not training:\n",
    "            loss.backward()\n",
    "        total_loss += loss\n",
    "        if epoch == epochs - 1:\n",
    "            avg_loss = total_loss / epochs\n",
    "            print(\"TRAINING [{}] LOSS: \", avg_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0118, -0.0528,  0.0469, -0.0351,  0.0411, -0.0126, -0.0037,  0.0009,\n",
      "         -0.0076,  0.0175, -0.0760,  0.0265, -0.0156, -0.0297, -0.0277,  0.0353,\n",
      "         -0.0104,  0.0131, -0.0030, -0.0387, -0.0597, -0.0299,  0.0071,  0.0607,\n",
      "         -0.0353,  0.0024, -0.0472,  0.0271,  0.0427,  0.0261, -0.0349, -0.0558,\n",
      "         -0.0338,  0.0505,  0.0317, -0.0137,  0.0288, -0.0307,  0.0297, -0.0469]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "DATASETS\\POLLUTION\\GEOGRAPHY_AIR_QUALITY_DATASET.pkl\n",
      "DATA:  <bound method NDFrame.head of       PM2.5   PM10     NO    NO2    Nox    NH3    CO    SO2     O3  Benzene  \\\n",
      "0     27.93  95.68   9.72   4.71  14.19   0.88  0.79   9.36  30.18     3.39   \n",
      "1     34.05  90.68  16.53   9.83  25.86   1.68  0.93   4.27  17.23     5.27   \n",
      "2     38.10  61.67   7.61   3.30  10.90   1.37  0.65  14.74  26.14     7.14   \n",
      "3     40.41  67.91  10.52   3.96  12.79   3.76  0.55   9.97  28.60     4.46   \n",
      "4     27.21  62.04   8.60   7.20  10.64   5.90  0.53   9.63  34.72     3.57   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...      ...   \n",
      "4949   7.63  32.27   5.91  23.27  17.19  11.15  0.46   6.87  19.90     1.45   \n",
      "4950  15.02  50.94   7.68  25.06  19.54  12.47  0.47   8.55  23.30     2.24   \n",
      "4951  24.38  74.09   3.42  26.06  16.53  11.99  0.52  12.72  30.14     0.74   \n",
      "4952  22.91  65.73   3.45  29.53  18.33  10.71  0.48   8.42  30.96     0.01   \n",
      "4953  16.64  49.97   4.05  29.26  18.80  10.03  0.52   9.84  28.30     0.00   \n",
      "\n",
      "      Toluene  Xylene   AQI      SCORE  \n",
      "0        0.04    3.82  93.0  20.932143  \n",
      "1        0.89   21.98  96.0  25.408571  \n",
      "2        1.94    2.15  88.0  18.097857  \n",
      "3        2.02    1.48  71.0  18.045000  \n",
      "4        2.08    1.32  69.0  16.512857  \n",
      "...       ...     ...   ...        ...  \n",
      "4949     5.37    1.45  47.0  15.065714  \n",
      "4950    12.07    0.73  41.0  16.542143  \n",
      "4951     2.21    0.38  70.0  19.061429  \n",
      "4952     0.01    0.00  68.0  18.931429  \n",
      "4953     0.00    0.00  54.0  16.459286  \n",
      "\n",
      "[4954 rows x 14 columns]>\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[22:39:58] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1258: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (13 vs. 40) : Number of columns does not match number of features in booster.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerator_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [3], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(epochs, generator)\u001b[0m\n\u001b[0;32m     16\u001b[0m valid_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Training Loop\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43miteration_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracies\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_accuracies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#Validation Loop\u001b[39;00m\n\u001b[0;32m     20\u001b[0m iteration_loop(training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, epochs \u001b[38;5;241m=\u001b[39m epochs, generator \u001b[38;5;241m=\u001b[39m generator, losses \u001b[38;5;241m=\u001b[39m valid_losses, accuracies \u001b[38;5;241m=\u001b[39m valid_accuracies)\n",
      "Cell \u001b[1;32mIn [3], line 43\u001b[0m, in \u001b[0;36miteration_loop\u001b[1;34m(training, epochs, generator, losses, accuracies)\u001b[0m\n\u001b[0;32m     39\u001b[0m sleep_metrics \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m37\u001b[39m:\u001b[38;5;241m40\u001b[39m]\n\u001b[0;32m     40\u001b[0m METRICS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpollution_gradient_tree\u001b[39m\u001b[38;5;124m'\u001b[39m : aq_metrics, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexercise\u001b[39m\u001b[38;5;124m'\u001b[39m: exercise_metrics,\n\u001b[0;32m     41\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnutrition_gradient_tree\u001b[39m\u001b[38;5;124m'\u001b[39m: nutrition_metrics, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_gradient_tree\u001b[39m\u001b[38;5;124m'\u001b[39m: sleep_metrics, \n\u001b[0;32m     42\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblood_gradient_tree\u001b[39m\u001b[38;5;124m'\u001b[39m: blood_report_metrics}\n\u001b[1;32m---> 43\u001b[0m avg_score \u001b[38;5;241m=\u001b[39m \u001b[43mget_avg_model_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m avg_score\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m training:\n",
      "File \u001b[1;32mc:\\Users\\mindf\\Documents\\PROFESSIONAL\\WORK\\HACKATHONS\\HACK THE NORTH\\hackthenorth\\ENSEMBLE_SCORING_ALGORITHM.py:46\u001b[0m, in \u001b[0;36mget_avg_model_score\u001b[1;34m(metrics)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m DATASETS\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m     <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=44'>45</a>\u001b[0m     \u001b[39mprint\u001b[39m(metrics[model])\n\u001b[1;32m---> <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=45'>46</a>\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m individual_model_score(DATASETS[model], model, metrics[model])\n\u001b[0;32m     <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=46'>47</a>\u001b[0m avg_score \u001b[39m=\u001b[39m total \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(DATASETS\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m     <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=47'>48</a>\u001b[0m \u001b[39mreturn\u001b[39;00m avg_score\n",
      "File \u001b[1;32mc:\\Users\\mindf\\Documents\\PROFESSIONAL\\WORK\\HACKATHONS\\HACK THE NORTH\\hackthenorth\\ENSEMBLE_SCORING_ALGORITHM.py:40\u001b[0m, in \u001b[0;36mindividual_model_score\u001b[1;34m(dataset, model, metrics)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=37'>38</a>\u001b[0m mx_data \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(data[\u001b[39m\"\u001b[39m\u001b[39mSCORE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=38'>39</a>\u001b[0m mn_data \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(data[\u001b[39m\"\u001b[39m\u001b[39mSCORE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='file:///c%3A/Users/mindf/Documents/PROFESSIONAL/WORK/HACKATHONS/HACK%20THE%20NORTH/hackthenorth/ENSEMBLE_SCORING_ALGORITHM.py?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scale(\u001b[39mglobals\u001b[39;49m()[model]\u001b[39m.\u001b[39;49mpredict(xgb\u001b[39m.\u001b[39;49mDMatrix(metrics\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mclone())), mx_data, mn_data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:1913\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1910'>1911</a>\u001b[0m shape \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mPOINTER(c_bst_ulong)()\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1911'>1912</a>\u001b[0m dims \u001b[39m=\u001b[39m c_bst_ulong()\n\u001b[1;32m-> <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1912'>1913</a>\u001b[0m _check_call(\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1913'>1914</a>\u001b[0m     _LIB\u001b[39m.\u001b[39;49mXGBoosterPredictFromDMatrix(\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1914'>1915</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1915'>1916</a>\u001b[0m         data\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1916'>1917</a>\u001b[0m         from_pystr_to_cstr(json\u001b[39m.\u001b[39;49mdumps(args)),\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1917'>1918</a>\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(shape),\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1918'>1919</a>\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(dims),\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1919'>1920</a>\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(preds)\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1920'>1921</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1921'>1922</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=1922'>1923</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:218\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=206'>207</a>\u001b[0m \u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=207'>208</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=208'>209</a>\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=214'>215</a>\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=215'>216</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=216'>217</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/mindf/anaconda3/lib/site-packages/xgboost/core.py?line=217'>218</a>\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [22:39:58] C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1258: Check failed: learner_model_param_.num_feature >= p_fmat->Info().num_col_ (13 vs. 40) : Number of columns does not match number of features in booster."
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train_model(epochs = 10, generator = generator_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb33c15c13a14f140d690812bf0a39a2e5e1e289641f45cea7a1bbeb79eff1a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
