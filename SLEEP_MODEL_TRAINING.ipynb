{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mindf\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv\n",
    "SLEEP_FITBIT_DATA = pd.read_csv(r'DATASETS\\SLEEP\\SLEEP_FITBIT_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      HOURS_OF_SLEEP  REM_SLEEP  DEEP_SLEEP  HEART_RATE_BELOW_RESTING  SCORE  \\\n",
       "0              7.22       0.18        0.21                      0.98    0.0   \n",
       "1              8.40       0.21        0.21                      0.73    0.0   \n",
       "2              8.52       0.21        0.17                      0.26    0.0   \n",
       "3              6.50       0.17        0.19                      0.99    0.0   \n",
       "4              6.57       0.18        0.21                      0.97    0.0   \n",
       "..              ...        ...         ...                       ...    ...   \n",
       "174            8.45       0.22        0.19                      0.56    0.0   \n",
       "175            7.53       0.24        0.19                      0.66    0.0   \n",
       "176            6.13       0.22        0.22                      0.81    0.0   \n",
       "177            7.44       0.18        0.21                      0.81    0.0   \n",
       "178            6.48       0.12        0.13                      0.74    0.0   \n",
       "\n",
       "     Unnamed: 5  Unnamed: 6  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "..          ...         ...  \n",
       "174         NaN         NaN  \n",
       "175         NaN         NaN  \n",
       "176         NaN         NaN  \n",
       "177         NaN         NaN  \n",
       "178         NaN         NaN  \n",
       "\n",
       "[179 rows x 7 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SLEEP_FITBIT_DATA.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =================================== \n",
      "7.22 8\n",
      "0.7800000000000002\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.3137500000000001\n",
      " =================================== \n",
      "8.4 8\n",
      "0.40000000000000036\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.73 0.58\n",
      "0.15000000000000002\n",
      "END SCORE:  0.1487500000000001\n",
      " =================================== \n",
      "8.52 8\n",
      "0.5199999999999996\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.26 0.58\n",
      "0.31999999999999995\n",
      "END SCORE:  0.2162499999999999\n",
      " =================================== \n",
      "6.5 8\n",
      "1.5\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.49375\n",
      " =================================== \n",
      "6.57 8\n",
      "1.4299999999999997\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.4737499999999999\n",
      " =================================== \n",
      "7.27 8\n",
      "0.7300000000000004\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.77 0.58\n",
      "0.19000000000000006\n",
      "END SCORE:  0.2462500000000001\n",
      " =================================== \n",
      "7.57 8\n",
      "0.4299999999999997\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.68 0.58\n",
      "0.10000000000000009\n",
      "END SCORE:  0.14374999999999993\n",
      " =================================== \n",
      "7.27 8\n",
      "0.7300000000000004\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.71 0.58\n",
      "0.13\n",
      "END SCORE:  0.22375000000000012\n",
      " =================================== \n",
      "8.12 8\n",
      "0.11999999999999922\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.71 0.58\n",
      "0.13\n",
      "END SCORE:  0.0787499999999998\n",
      " =================================== \n",
      "6.57 8\n",
      "1.4299999999999997\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.47124999999999995\n",
      " =================================== \n",
      "7.39 8\n",
      "0.6100000000000003\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.26875000000000004\n",
      " =================================== \n",
      "8.0 8\n",
      "0.0\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.73 0.58\n",
      "0.15000000000000002\n",
      "END SCORE:  0.046250000000000006\n",
      " =================================== \n",
      "7.48 8\n",
      "0.5199999999999996\n",
      "0.11 0.225\n",
      "0.115\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.73 0.58\n",
      "0.15000000000000002\n",
      "END SCORE:  0.2087499999999999\n",
      " =================================== \n",
      "7.19 8\n",
      "0.8099999999999996\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.23 0.18\n",
      "0.05000000000000002\n",
      "0.77 0.58\n",
      "0.19000000000000006\n",
      "END SCORE:  0.27124999999999994\n",
      " =================================== \n",
      "8.04 8\n",
      "0.03999999999999915\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.57 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.02874999999999979\n",
      " =================================== \n",
      "9.39 8\n",
      "1.3900000000000006\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.4487500000000002\n",
      " =================================== \n",
      "7.32 8\n",
      "0.6799999999999997\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.2862499999999999\n",
      " =================================== \n",
      "7.59 8\n",
      "0.41000000000000014\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.20875000000000005\n",
      " =================================== \n",
      "7.59 8\n",
      "0.41000000000000014\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.45 0.58\n",
      "0.12999999999999995\n",
      "END SCORE:  0.15625\n",
      " =================================== \n",
      "6.54 8\n",
      "1.46\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.09 0.58\n",
      "0.49\n",
      "END SCORE:  0.50125\n",
      " =================================== \n",
      "7.59 8\n",
      "0.41000000000000014\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.24 0.18\n",
      "0.06\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.22125000000000006\n",
      " =================================== \n",
      "7.44 8\n",
      "0.5599999999999996\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.08 0.18\n",
      "0.09999999999999999\n",
      "0.88 0.58\n",
      "0.30000000000000004\n",
      "END SCORE:  0.24874999999999992\n",
      " =================================== \n",
      "7.55 8\n",
      "0.4500000000000002\n",
      "0.08 0.225\n",
      "0.14500000000000002\n",
      "0.12 0.18\n",
      "0.06\n",
      "0.57 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.16625000000000006\n",
      " =================================== \n",
      "8.17 8\n",
      "0.16999999999999993\n",
      "0.13 0.225\n",
      "0.095\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.64 0.58\n",
      "0.06000000000000005\n",
      "END SCORE:  0.08875\n",
      " =================================== \n",
      "7.39 8\n",
      "0.6100000000000003\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.7 0.58\n",
      "0.12\n",
      "END SCORE:  0.20375000000000007\n",
      " =================================== \n",
      "7.18 8\n",
      "0.8200000000000003\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "1.0 0.58\n",
      "0.42000000000000004\n",
      "END SCORE:  0.32125000000000004\n",
      " =================================== \n",
      "7.34 8\n",
      "0.6600000000000001\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.27125000000000005\n",
      " =================================== \n",
      "6.54 8\n",
      "1.46\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.9 0.58\n",
      "0.32000000000000006\n",
      "END SCORE:  0.45875000000000005\n",
      " =================================== \n",
      "7.45 8\n",
      "0.5499999999999998\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.24124999999999996\n",
      " =================================== \n",
      "7.11 8\n",
      "0.8899999999999997\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.75 0.58\n",
      "0.17000000000000004\n",
      "END SCORE:  0.26624999999999993\n",
      " =================================== \n",
      "7.33 8\n",
      "0.6699999999999999\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.27125\n",
      " =================================== \n",
      "7.17 8\n",
      "0.8300000000000001\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.94 0.58\n",
      "0.36\n",
      "END SCORE:  0.32625000000000004\n",
      " =================================== \n",
      "7.17 8\n",
      "0.8300000000000001\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.78 0.58\n",
      "0.20000000000000007\n",
      "END SCORE:  0.27875000000000005\n",
      " =================================== \n",
      "8.23 8\n",
      "0.23000000000000043\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.58 0.58\n",
      "0.0\n",
      "END SCORE:  0.07125000000000012\n",
      " =================================== \n",
      "7.19 8\n",
      "0.8099999999999996\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.12 0.18\n",
      "0.06\n",
      "0.79 0.58\n",
      "0.21000000000000008\n",
      "END SCORE:  0.2762499999999999\n",
      " =================================== \n",
      "7.18 8\n",
      "0.8200000000000003\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.56 0.58\n",
      "0.019999999999999907\n",
      "END SCORE:  0.22625000000000006\n",
      " =================================== \n",
      "8.02 8\n",
      "0.019999999999999574\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.11 0.18\n",
      "0.06999999999999999\n",
      "0.94 0.58\n",
      "0.36\n",
      "END SCORE:  0.1162499999999999\n",
      " =================================== \n",
      "6.47 8\n",
      "1.5300000000000002\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.94 0.58\n",
      "0.36\n",
      "END SCORE:  0.47875\n",
      " =================================== \n",
      "7.32 8\n",
      "0.6799999999999997\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.3012499999999999\n",
      " =================================== \n",
      "7.45 8\n",
      "0.5499999999999998\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.75 0.58\n",
      "0.17000000000000004\n",
      "END SCORE:  0.19874999999999995\n",
      " =================================== \n",
      "7.57 8\n",
      "0.4299999999999997\n",
      "0.13 0.225\n",
      "0.095\n",
      "0.1 0.18\n",
      "0.07999999999999999\n",
      "0.45 0.58\n",
      "0.12999999999999995\n",
      "END SCORE:  0.1837499999999999\n",
      " =================================== \n",
      "6.47 8\n",
      "1.5300000000000002\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.74 0.58\n",
      "0.16000000000000003\n",
      "END SCORE:  0.4287500000000001\n",
      " =================================== \n",
      "8.33 8\n",
      "0.33000000000000007\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.83 0.58\n",
      "0.25\n",
      "END SCORE:  0.15625000000000003\n",
      " =================================== \n",
      "7.33 8\n",
      "0.6699999999999999\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.76 0.58\n",
      "0.18000000000000005\n",
      "END SCORE:  0.24375\n",
      " =================================== \n",
      "7.08 8\n",
      "0.9199999999999999\n",
      "0.26 0.225\n",
      "0.035\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.31 0.58\n",
      "0.26999999999999996\n",
      "END SCORE:  0.30874999999999997\n",
      " =================================== \n",
      "6.34 8\n",
      "1.6600000000000001\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.23 0.18\n",
      "0.05000000000000002\n",
      "0.0 0.58\n",
      "0.58\n",
      "END SCORE:  0.58875\n",
      " =================================== \n",
      "7.18 8\n",
      "0.8200000000000003\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.79 0.58\n",
      "0.21000000000000008\n",
      "END SCORE:  0.2662500000000001\n",
      " =================================== \n",
      "8.14 8\n",
      "0.14000000000000057\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.15375000000000016\n",
      " =================================== \n",
      "7.08 8\n",
      "0.9199999999999999\n",
      "0.29 0.225\n",
      "0.06499999999999997\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.65 0.58\n",
      "0.07000000000000006\n",
      "END SCORE:  0.26625\n",
      " =================================== \n",
      "7.06 8\n",
      "0.9400000000000004\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.34625000000000006\n",
      " =================================== \n",
      "8.26 8\n",
      "0.2599999999999998\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.16624999999999995\n",
      " =================================== \n",
      "7.29 8\n",
      "0.71\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.9 0.58\n",
      "0.32000000000000006\n",
      "END SCORE:  0.26375000000000004\n",
      " =================================== \n",
      "8.37 8\n",
      "0.3699999999999992\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.1937499999999998\n",
      " =================================== \n",
      "9.03 8\n",
      "1.0299999999999994\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.52 0.58\n",
      "0.05999999999999994\n",
      "END SCORE:  0.29874999999999985\n",
      " =================================== \n",
      "6.39 8\n",
      "1.6100000000000003\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.5 0.58\n",
      "0.07999999999999996\n",
      "END SCORE:  0.4487500000000001\n",
      " =================================== \n",
      "7.51 8\n",
      "0.4900000000000002\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.27 0.18\n",
      "0.09000000000000002\n",
      "0.83 0.58\n",
      "0.25\n",
      "END SCORE:  0.21125000000000005\n",
      " =================================== \n",
      "7.06 8\n",
      "0.9400000000000004\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.9 0.58\n",
      "0.32000000000000006\n",
      "END SCORE:  0.32625000000000015\n",
      " =================================== \n",
      "6.57 8\n",
      "1.4299999999999997\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.46624999999999994\n",
      " =================================== \n",
      "7.23 8\n",
      "0.7699999999999996\n",
      "0.26 0.225\n",
      "0.035\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.3062499999999999\n",
      " =================================== \n",
      "7.48 8\n",
      "0.5199999999999996\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.6 0.58\n",
      "0.020000000000000018\n",
      "END SCORE:  0.1437499999999999\n",
      " =================================== \n",
      "8.09 8\n",
      "0.08999999999999986\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.7 0.58\n",
      "0.12\n",
      "END SCORE:  0.05624999999999997\n",
      " =================================== \n",
      "4.13 8\n",
      "3.87\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.0 0.58\n",
      "0.58\n",
      "END SCORE:  1.13125\n",
      " =================================== \n",
      "8.09 8\n",
      "0.08999999999999986\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.92 0.58\n",
      "0.3400000000000001\n",
      "END SCORE:  0.10874999999999999\n",
      " =================================== \n",
      "7.27 8\n",
      "0.7300000000000004\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.30625000000000013\n",
      " =================================== \n",
      "7.25 8\n",
      "0.75\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.30625\n",
      " =================================== \n",
      "7.1 8\n",
      "0.9000000000000004\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.89 0.58\n",
      "0.31000000000000005\n",
      "END SCORE:  0.32125000000000015\n",
      " =================================== \n",
      "6.46 8\n",
      "1.54\n",
      "0.14 0.225\n",
      "0.08499999999999999\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.50625\n",
      " =================================== \n",
      "6.48 8\n",
      "1.5199999999999996\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.49124999999999985\n",
      " =================================== \n",
      "7.37 8\n",
      "0.6299999999999999\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.28625\n",
      " =================================== \n",
      "7.47 8\n",
      "0.5300000000000002\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.12 0.18\n",
      "0.06\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.25375000000000003\n",
      " =================================== \n",
      "7.26 8\n",
      "0.7400000000000002\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.28125000000000006\n",
      " =================================== \n",
      "6.59 8\n",
      "1.4100000000000001\n",
      "0.31 0.225\n",
      "0.08499999999999999\n",
      "0.24 0.18\n",
      "0.06\n",
      "0.71 0.58\n",
      "0.13\n",
      "END SCORE:  0.42125\n",
      " =================================== \n",
      "8.08 8\n",
      "0.08000000000000007\n",
      "0.27 0.225\n",
      "0.04500000000000001\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.13625000000000004\n",
      " =================================== \n",
      "7.32 8\n",
      "0.6799999999999997\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.93 0.58\n",
      "0.3500000000000001\n",
      "END SCORE:  0.26374999999999993\n",
      " =================================== \n",
      "7.1 8\n",
      "0.9000000000000004\n",
      "0.25 0.225\n",
      "0.024999999999999994\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.86 0.58\n",
      "0.28\n",
      "END SCORE:  0.3037500000000001\n",
      " =================================== \n",
      "7.14 8\n",
      "0.8600000000000003\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.68 0.58\n",
      "0.10000000000000009\n",
      "END SCORE:  0.2412500000000001\n",
      " =================================== \n",
      "7.26 8\n",
      "0.7400000000000002\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.86 0.58\n",
      "0.28\n",
      "END SCORE:  0.2712500000000001\n",
      " =================================== \n",
      "8.05 8\n",
      "0.05000000000000071\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.58 0.58\n",
      "0.0\n",
      "END SCORE:  0.023750000000000174\n",
      " =================================== \n",
      "7.12 8\n",
      "0.8799999999999999\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.72 0.58\n",
      "0.14\n",
      "END SCORE:  0.26125\n",
      " =================================== \n",
      "7.56 8\n",
      "0.4400000000000004\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.2262500000000001\n",
      " =================================== \n",
      "8.42 8\n",
      "0.41999999999999993\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.94 0.58\n",
      "0.36\n",
      "END SCORE:  0.20875\n",
      " =================================== \n",
      "6.28 8\n",
      "1.7199999999999998\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.53625\n",
      " =================================== \n",
      "8.04 8\n",
      "0.03999999999999915\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.57 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.016249999999999785\n",
      " =================================== \n",
      "8.04 8\n",
      "0.03999999999999915\n",
      "0.26 0.225\n",
      "0.035\n",
      "0.23 0.18\n",
      "0.05000000000000002\n",
      "0.54 0.58\n",
      "0.039999999999999925\n",
      "END SCORE:  0.04124999999999977\n",
      " =================================== \n",
      "7.45 8\n",
      "0.5499999999999998\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.23124999999999996\n",
      " =================================== \n",
      "7.39 8\n",
      "0.6100000000000003\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.74 0.58\n",
      "0.16000000000000003\n",
      "END SCORE:  0.2012500000000001\n",
      " =================================== \n",
      "7.09 8\n",
      "0.9100000000000001\n",
      "0.25 0.225\n",
      "0.024999999999999994\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.33625000000000005\n",
      " =================================== \n",
      "6.52 8\n",
      "1.4800000000000004\n",
      "0.26 0.225\n",
      "0.035\n",
      "0.24 0.18\n",
      "0.06\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.48875000000000013\n",
      " =================================== \n",
      "7.42 8\n",
      "0.5800000000000001\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.92 0.58\n",
      "0.3400000000000001\n",
      "END SCORE:  0.23625000000000004\n",
      " =================================== \n",
      "7.37 8\n",
      "0.6299999999999999\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.57 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.16624999999999998\n",
      " =================================== \n",
      "8.27 8\n",
      "0.2699999999999996\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.12 0.18\n",
      "0.06\n",
      "0.71 0.58\n",
      "0.13\n",
      "END SCORE:  0.14124999999999988\n",
      " =================================== \n",
      "7.21 8\n",
      "0.79\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.59 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.22375\n",
      " =================================== \n",
      "7.3 8\n",
      "0.7000000000000002\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.28875000000000006\n",
      " =================================== \n",
      "7.27 8\n",
      "0.7300000000000004\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.88 0.58\n",
      "0.30000000000000004\n",
      "END SCORE:  0.26375000000000015\n",
      " =================================== \n",
      "5.39 8\n",
      "2.6100000000000003\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.0 0.18\n",
      "0.18\n",
      "0.13 0.58\n",
      "0.44999999999999996\n",
      "END SCORE:  0.8262500000000002\n",
      " =================================== \n",
      "9.13 8\n",
      "1.1300000000000008\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.3912500000000002\n",
      " =================================== \n",
      "6.5 8\n",
      "1.5\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.93 0.58\n",
      "0.3500000000000001\n",
      "END SCORE:  0.46625\n",
      " =================================== \n",
      "6.43 8\n",
      "1.5700000000000003\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.7 0.58\n",
      "0.12\n",
      "END SCORE:  0.43625\n",
      " =================================== \n",
      "8.16 8\n",
      "0.16000000000000014\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.79 0.58\n",
      "0.21000000000000008\n",
      "END SCORE:  0.10875000000000005\n",
      " =================================== \n",
      "6.41 8\n",
      "1.5899999999999999\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.94 0.58\n",
      "0.36\n",
      "END SCORE:  0.49624999999999997\n",
      " =================================== \n",
      "7.18 8\n",
      "0.8200000000000003\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.89 0.58\n",
      "0.31000000000000005\n",
      "END SCORE:  0.29875000000000007\n",
      " =================================== \n",
      "6.35 8\n",
      "1.6500000000000004\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.85 0.58\n",
      "0.27\n",
      "END SCORE:  0.4937500000000001\n",
      " =================================== \n",
      "8.51 8\n",
      "0.5099999999999998\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.42 0.58\n",
      "0.15999999999999998\n",
      "END SCORE:  0.17624999999999996\n",
      " =================================== \n",
      "8.49 8\n",
      "0.4900000000000002\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.35 0.58\n",
      "0.22999999999999998\n",
      "END SCORE:  0.18375000000000005\n",
      " =================================== \n",
      "8.04 8\n",
      "0.03999999999999915\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.11624999999999978\n",
      " =================================== \n",
      "6.42 8\n",
      "1.58\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.52 0.58\n",
      "0.05999999999999994\n",
      "END SCORE:  0.42625\n",
      " =================================== \n",
      "7.07 8\n",
      "0.9299999999999997\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.35624999999999996\n",
      " =================================== \n",
      "6.49 8\n",
      "1.5099999999999998\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.49624999999999997\n",
      " =================================== \n",
      "8.01 8\n",
      "0.009999999999999787\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.89 0.58\n",
      "0.31000000000000005\n",
      "END SCORE:  0.09124999999999996\n",
      " =================================== \n",
      "6.54 8\n",
      "1.46\n",
      "0.13 0.225\n",
      "0.095\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.77 0.58\n",
      "0.19000000000000006\n",
      "END SCORE:  0.44375\n",
      " =================================== \n",
      "8.18 8\n",
      "0.17999999999999972\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.71 0.58\n",
      "0.13\n",
      "END SCORE:  0.08374999999999994\n",
      " =================================== \n",
      "8.04 8\n",
      "0.03999999999999915\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.76 0.58\n",
      "0.18000000000000005\n",
      "END SCORE:  0.07624999999999979\n",
      " =================================== \n",
      "8.12 8\n",
      "0.11999999999999922\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.4 0.58\n",
      "0.17999999999999994\n",
      "END SCORE:  0.08874999999999979\n",
      " =================================== \n",
      "7.49 8\n",
      "0.5099999999999998\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.23124999999999996\n",
      " =================================== \n",
      "7.16 8\n",
      "0.8399999999999999\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.31875\n",
      " =================================== \n",
      "7.18 8\n",
      "0.8200000000000003\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.3112500000000001\n",
      " =================================== \n",
      "7.46 8\n",
      "0.54\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.24875000000000003\n",
      " =================================== \n",
      "8.02 8\n",
      "0.019999999999999574\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.57 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.028749999999999894\n",
      " =================================== \n",
      "8.54 8\n",
      "0.5399999999999991\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.81 0.58\n",
      "0.2300000000000001\n",
      "END SCORE:  0.20624999999999982\n",
      " =================================== \n",
      "7.57 8\n",
      "0.4299999999999997\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.54 0.58\n",
      "0.039999999999999925\n",
      "END SCORE:  0.1387499999999999\n",
      " =================================== \n",
      "6.47 8\n",
      "1.5300000000000002\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.91 0.58\n",
      "0.33000000000000007\n",
      "END SCORE:  0.48125000000000007\n",
      " =================================== \n",
      "7.36 8\n",
      "0.6399999999999997\n",
      "0.14 0.225\n",
      "0.08499999999999999\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.2812499999999999\n",
      " =================================== \n",
      "7.59 8\n",
      "0.41000000000000014\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.44 0.58\n",
      "0.13999999999999996\n",
      "END SCORE:  0.15625000000000003\n",
      " =================================== \n",
      "8.29 8\n",
      "0.28999999999999915\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.99 0.58\n",
      "0.41000000000000003\n",
      "END SCORE:  0.19874999999999982\n",
      " =================================== \n",
      "8.3 8\n",
      "0.3000000000000007\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.72 0.58\n",
      "0.14\n",
      "END SCORE:  0.11875000000000019\n",
      " =================================== \n",
      "7.29 8\n",
      "0.71\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.69 0.58\n",
      "0.10999999999999999\n",
      "END SCORE:  0.21625\n",
      " =================================== \n",
      "5.42 8\n",
      "2.58\n",
      "0.13 0.225\n",
      "0.095\n",
      "0.0 0.18\n",
      "0.18\n",
      "0.59 0.58\n",
      "0.010000000000000009\n",
      "END SCORE:  0.71625\n",
      " =================================== \n",
      "8.22 8\n",
      "0.22000000000000064\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.43 0.58\n",
      "0.14999999999999997\n",
      "END SCORE:  0.11625000000000014\n",
      " =================================== \n",
      "7.59 8\n",
      "0.41000000000000014\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.92 0.58\n",
      "0.3400000000000001\n",
      "END SCORE:  0.20375000000000004\n",
      " =================================== \n",
      "8.13 8\n",
      "0.13000000000000078\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.84 0.58\n",
      "0.26\n",
      "END SCORE:  0.1262500000000002\n",
      " =================================== \n",
      "7.37 8\n",
      "0.6299999999999999\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.36 0.58\n",
      "0.21999999999999997\n",
      "END SCORE:  0.22874999999999998\n",
      " =================================== \n",
      "7.28 8\n",
      "0.7199999999999998\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.54 0.58\n",
      "0.039999999999999925\n",
      "END SCORE:  0.19874999999999993\n",
      " =================================== \n",
      "7.14 8\n",
      "0.8600000000000003\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.76 0.58\n",
      "0.18000000000000005\n",
      "END SCORE:  0.2762500000000001\n",
      " =================================== \n",
      "7.33 8\n",
      "0.6699999999999999\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.25 0.18\n",
      "0.07\n",
      "0.87 0.58\n",
      "0.29000000000000004\n",
      "END SCORE:  0.26375\n",
      " =================================== \n",
      "7.47 8\n",
      "0.5300000000000002\n",
      "0.25 0.225\n",
      "0.024999999999999994\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.89 0.58\n",
      "0.31000000000000005\n",
      "END SCORE:  0.22125000000000009\n",
      " =================================== \n",
      "8.17 8\n",
      "0.16999999999999993\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.93 0.58\n",
      "0.3500000000000001\n",
      "END SCORE:  0.14125\n",
      " =================================== \n",
      "7.12 8\n",
      "0.8799999999999999\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.8 0.58\n",
      "0.22000000000000008\n",
      "END SCORE:  0.30625\n",
      " =================================== \n",
      "8.16 8\n",
      "0.16000000000000014\n",
      "0.27 0.225\n",
      "0.04500000000000001\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.67 0.58\n",
      "0.09000000000000008\n",
      "END SCORE:  0.07375000000000007\n",
      " =================================== \n",
      "8.09 8\n",
      "0.08999999999999986\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.91 0.58\n",
      "0.33000000000000007\n",
      "END SCORE:  0.13124999999999998\n",
      " =================================== \n",
      "7.07 8\n",
      "0.9299999999999997\n",
      "0.25 0.225\n",
      "0.024999999999999994\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.33874999999999994\n",
      " =================================== \n",
      "7.25 8\n",
      "0.75\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.43 0.58\n",
      "0.14999999999999997\n",
      "END SCORE:  0.23875000000000002\n",
      " =================================== \n",
      "7.52 8\n",
      "0.4800000000000004\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.52 0.58\n",
      "0.05999999999999994\n",
      "END SCORE:  0.1387500000000001\n",
      " =================================== \n",
      "8.1 8\n",
      "0.09999999999999964\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.1 0.58\n",
      "0.48\n",
      "END SCORE:  0.1662499999999999\n",
      " =================================== \n",
      "8.54 8\n",
      "0.5399999999999991\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.11 0.18\n",
      "0.06999999999999999\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.25624999999999976\n",
      " =================================== \n",
      "7.03 8\n",
      "0.9699999999999998\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.3487499999999999\n",
      " =================================== \n",
      "6.33 8\n",
      "1.67\n",
      "0.14 0.225\n",
      "0.08499999999999999\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.54125\n",
      " =================================== \n",
      "6.59 8\n",
      "1.4100000000000001\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.23 0.18\n",
      "0.05000000000000002\n",
      "0.93 0.58\n",
      "0.3500000000000001\n",
      "END SCORE:  0.45375000000000004\n",
      " =================================== \n",
      "6.34 8\n",
      "1.6600000000000001\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.52125\n",
      " =================================== \n",
      "7.38 8\n",
      "0.6200000000000001\n",
      "0.3 0.225\n",
      "0.07499999999999998\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.92 0.58\n",
      "0.3400000000000001\n",
      "END SCORE:  0.26625000000000004\n",
      " =================================== \n",
      "8.06 8\n",
      "0.0600000000000005\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.84 0.58\n",
      "0.26\n",
      "END SCORE:  0.09875000000000012\n",
      " =================================== \n",
      "7.57 8\n",
      "0.4299999999999997\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.18 0.18\n",
      "0.0\n",
      "0.9 0.58\n",
      "0.32000000000000006\n",
      "END SCORE:  0.21374999999999994\n",
      " =================================== \n",
      "7.06 8\n",
      "0.9400000000000004\n",
      "0.13 0.225\n",
      "0.095\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.93 0.58\n",
      "0.3500000000000001\n",
      "END SCORE:  0.3562500000000001\n",
      " =================================== \n",
      "7.04 8\n",
      "0.96\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.34875\n",
      " =================================== \n",
      "9.24 8\n",
      "1.2400000000000002\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.66 0.58\n",
      "0.08000000000000007\n",
      "END SCORE:  0.35125000000000006\n",
      " =================================== \n",
      "8.19 8\n",
      "0.1899999999999995\n",
      "0.14 0.225\n",
      "0.08499999999999999\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.21 0.58\n",
      "0.37\n",
      "END SCORE:  0.17374999999999985\n",
      " =================================== \n",
      "7.37 8\n",
      "0.6299999999999999\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.15 0.18\n",
      "0.03\n",
      "0.8 0.58\n",
      "0.22000000000000008\n",
      "END SCORE:  0.22625\n",
      " =================================== \n",
      "6.46 8\n",
      "1.54\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.89 0.58\n",
      "0.31000000000000005\n",
      "END SCORE:  0.48125\n",
      " =================================== \n",
      "7.1 8\n",
      "0.9000000000000004\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.3312500000000001\n",
      " =================================== \n",
      "7.16 8\n",
      "0.8399999999999999\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.31124999999999997\n",
      " =================================== \n",
      "6.52 8\n",
      "1.4800000000000004\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.97 0.58\n",
      "0.39\n",
      "END SCORE:  0.4837500000000001\n",
      " =================================== \n",
      "7.28 8\n",
      "0.7199999999999998\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.74 0.58\n",
      "0.16000000000000003\n",
      "END SCORE:  0.23624999999999996\n",
      " =================================== \n",
      "6.06 8\n",
      "1.9400000000000004\n",
      "0.16 0.225\n",
      "0.065\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.43 0.58\n",
      "0.14999999999999997\n",
      "END SCORE:  0.54625\n",
      " =================================== \n",
      "6.59 8\n",
      "1.4100000000000001\n",
      "0.23 0.225\n",
      "0.0050000000000000044\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.91 0.58\n",
      "0.33000000000000007\n",
      "END SCORE:  0.44625000000000004\n",
      " =================================== \n",
      "7.19 8\n",
      "0.8099999999999996\n",
      "0.21 0.225\n",
      "0.015000000000000013\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.96 0.58\n",
      "0.38\n",
      "END SCORE:  0.3112499999999999\n",
      " =================================== \n",
      "7.22 8\n",
      "0.7800000000000002\n",
      "0.17 0.225\n",
      "0.05499999999999999\n",
      "0.11 0.18\n",
      "0.06999999999999999\n",
      "0.55 0.58\n",
      "0.029999999999999916\n",
      "END SCORE:  0.23375\n",
      " =================================== \n",
      "6.57 8\n",
      "1.4299999999999997\n",
      "0.15 0.225\n",
      "0.07500000000000001\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.67 0.58\n",
      "0.09000000000000008\n",
      "END SCORE:  0.40874999999999995\n",
      " =================================== \n",
      "7.14 8\n",
      "0.8600000000000003\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.98 0.58\n",
      "0.4\n",
      "END SCORE:  0.3212500000000001\n",
      " =================================== \n",
      "6.5 8\n",
      "1.5\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.2 0.18\n",
      "0.020000000000000018\n",
      "0.75 0.58\n",
      "0.17000000000000004\n",
      "END SCORE:  0.42874999999999996\n",
      " =================================== \n",
      "7.56 8\n",
      "0.4400000000000004\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.63 0.58\n",
      "0.050000000000000044\n",
      "END SCORE:  0.12875000000000011\n",
      " =================================== \n",
      "7.33 8\n",
      "0.6699999999999999\n",
      "0.19 0.225\n",
      "0.035\n",
      "0.16 0.18\n",
      "0.01999999999999999\n",
      "0.95 0.58\n",
      "0.37\n",
      "END SCORE:  0.27375\n",
      " =================================== \n",
      "8.21 8\n",
      "0.21000000000000085\n",
      "0.14 0.225\n",
      "0.08499999999999999\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.94 0.58\n",
      "0.36\n",
      "END SCORE:  0.1662500000000002\n",
      " =================================== \n",
      "8.15 8\n",
      "0.15000000000000036\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.14 0.18\n",
      "0.03999999999999998\n",
      "0.72 0.58\n",
      "0.14\n",
      "END SCORE:  0.08875000000000008\n",
      " =================================== \n",
      "6.26 8\n",
      "1.7400000000000002\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.55 0.58\n",
      "0.029999999999999916\n",
      "END SCORE:  0.46625000000000005\n",
      " =================================== \n",
      "6.51 8\n",
      "1.4900000000000002\n",
      "0.2 0.225\n",
      "0.024999999999999994\n",
      "0.17 0.18\n",
      "0.009999999999999981\n",
      "0.51 0.58\n",
      "0.06999999999999995\n",
      "END SCORE:  0.39875000000000005\n",
      " =================================== \n",
      "8.45 8\n",
      "0.4499999999999993\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.56 0.58\n",
      "0.019999999999999907\n",
      "END SCORE:  0.1212499999999998\n",
      " =================================== \n",
      "7.53 8\n",
      "0.46999999999999975\n",
      "0.24 0.225\n",
      "0.014999999999999986\n",
      "0.19 0.18\n",
      "0.010000000000000009\n",
      "0.66 0.58\n",
      "0.08000000000000007\n",
      "END SCORE:  0.14374999999999996\n",
      " =================================== \n",
      "6.13 8\n",
      "1.87\n",
      "0.22 0.225\n",
      "0.0050000000000000044\n",
      "0.22 0.18\n",
      "0.04000000000000001\n",
      "0.81 0.58\n",
      "0.2300000000000001\n",
      "END SCORE:  0.53625\n",
      " =================================== \n",
      "7.44 8\n",
      "0.5599999999999996\n",
      "0.18 0.225\n",
      "0.04500000000000001\n",
      "0.21 0.18\n",
      "0.03\n",
      "0.81 0.58\n",
      "0.2300000000000001\n",
      "END SCORE:  0.21624999999999994\n",
      " =================================== \n",
      "6.48 8\n",
      "1.5199999999999996\n",
      "0.12 0.225\n",
      "0.10500000000000001\n",
      "0.13 0.18\n",
      "0.04999999999999999\n",
      "0.74 0.58\n",
      "0.16000000000000003\n",
      "END SCORE:  0.4587499999999999\n"
     ]
    }
   ],
   "source": [
    "#Create dictionary of ideal values for each score; calculate L2 norm to generate score)\n",
    "IDEAL_VALS = {'HOURS_OF_SLEEP': 8, 'REM_SLEEP': 0.225, 'DEEP_SLEEP': 0.18, 'HEART_RATE_BELOW_RESTING': 0.58}\n",
    "columns = SLEEP_FITBIT_DATA.columns.values.tolist()\n",
    "columns = columns[:4]\n",
    "#Generate scores for each lever - compare iteratively and generate average score on its basis\n",
    "def generate_score(row):\n",
    "    #Iterate over each column except for gender\n",
    "    print(\" =================================== \")\n",
    "    total_score = 0\n",
    "    for column in columns:\n",
    "        if column == \"SCORE\": continue\n",
    "        print(row[column], IDEAL_VALS[column])\n",
    "        column_score = abs(row[column] - IDEAL_VALS[column])\n",
    "        print(column_score)\n",
    "        total_score += column_score\n",
    "    #Average out the score\n",
    "    row[\"SCORE\"] = total_score / len(columns)\n",
    "    print('END SCORE: ', row[\"SCORE\"])\n",
    "    return row\n",
    "\n",
    "SLEEP_FITBIT_DATA = SLEEP_FITBIT_DATA.apply(generate_score, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HOURS_OF_SLEEP  REM_SLEEP  DEEP_SLEEP  HEART_RATE_BELOW_RESTING    SCORE  \\\n",
      "0              7.22       0.18        0.21                      0.98  0.31375   \n",
      "1              8.40       0.21        0.21                      0.73  0.14875   \n",
      "2              8.52       0.21        0.17                      0.26  0.21625   \n",
      "3              6.50       0.17        0.19                      0.99  0.49375   \n",
      "4              6.57       0.18        0.21                      0.97  0.47375   \n",
      "..              ...        ...         ...                       ...      ...   \n",
      "174            8.45       0.22        0.19                      0.56  0.12125   \n",
      "175            7.53       0.24        0.19                      0.66  0.14375   \n",
      "176            6.13       0.22        0.22                      0.81  0.53625   \n",
      "177            7.44       0.18        0.21                      0.81  0.21625   \n",
      "178            6.48       0.12        0.13                      0.74  0.45875   \n",
      "\n",
      "     Unnamed: 5  Unnamed: 6  \n",
      "0           NaN         NaN  \n",
      "1           NaN         NaN  \n",
      "2           NaN         NaN  \n",
      "3           NaN         NaN  \n",
      "4           NaN         NaN  \n",
      "..          ...         ...  \n",
      "174         NaN         NaN  \n",
      "175         NaN         NaN  \n",
      "176         NaN         NaN  \n",
      "177         NaN         NaN  \n",
      "178         NaN         NaN  \n",
      "\n",
      "[179 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(SLEEP_FITBIT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      HOURS_OF_SLEEP  REM_SLEEP  DEEP_SLEEP  HEART_RATE_BELOW_RESTING    SCORE  \\\n",
      "0              7.22       0.18        0.21                      0.98  0.31375   \n",
      "1              8.40       0.21        0.21                      0.73  0.14875   \n",
      "2              8.52       0.21        0.17                      0.26  0.21625   \n",
      "3              6.50       0.17        0.19                      0.99  0.49375   \n",
      "4              6.57       0.18        0.21                      0.97  0.47375   \n",
      "..              ...        ...         ...                       ...      ...   \n",
      "174            8.45       0.22        0.19                      0.56  0.12125   \n",
      "175            7.53       0.24        0.19                      0.66  0.14375   \n",
      "176            6.13       0.22        0.22                      0.81  0.53625   \n",
      "177            7.44       0.18        0.21                      0.81  0.21625   \n",
      "178            6.48       0.12        0.13                      0.74  0.45875   \n",
      "\n",
      "     Unnamed: 5  Unnamed: 6  \n",
      "0           NaN         NaN  \n",
      "1           NaN         NaN  \n",
      "2           NaN         NaN  \n",
      "3           NaN         NaN  \n",
      "4           NaN         NaN  \n",
      "..          ...         ...  \n",
      "174         NaN         NaN  \n",
      "175         NaN         NaN  \n",
      "176         NaN         NaN  \n",
      "177         NaN         NaN  \n",
      "178         NaN         NaN  \n",
      "\n",
      "[179 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(SLEEP_FITBIT_DATA.head)\n",
    "SLEEP_FITBIT_DATA.to_pickle('PREPROCESSED_SLEEP_FITBIT_DATA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HOURS_OF_SLEEP  REM_SLEEP  DEEP_SLEEP\n",
      "0              7.22       0.18        0.21\n",
      "1              8.40       0.21        0.21\n",
      "2              8.52       0.21        0.17\n",
      "3              6.50       0.17        0.19\n",
      "4              6.57       0.18        0.21\n",
      "..              ...        ...         ...\n",
      "174            8.45       0.22        0.19\n",
      "175            7.53       0.24        0.19\n",
      "176            6.13       0.22        0.22\n",
      "177            7.44       0.18        0.21\n",
      "178            6.48       0.12        0.13\n",
      "\n",
      "[179 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reshape tensors for XGBOOST\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_features = SLEEP_FITBIT_DATA.iloc[:, :3]\n",
    "print(x_features)\n",
    "y_labels = SLEEP_FITBIT_DATA[\"SCORE\"]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x_features, y_labels, random_state = 2, shuffle = True)\n",
    "\n",
    "train_x = tf.convert_to_tensor(train_x)\n",
    "train_x = tf.reshape(train_x, [len(train_x), 3])\n",
    "\n",
    "valid_x = tf.convert_to_tensor(valid_x)\n",
    "valid_x = tf.reshape(valid_x, [len(valid_x), 3])\n",
    "\n",
    "train_y = tf.convert_to_tensor(train_y)\n",
    "train_y = tf.reshape(train_y, [len(train_y), 1])\n",
    "\n",
    "valid_y = tf.convert_to_tensor(valid_y)\n",
    "valid_y = tf.reshape(valid_y, [len(valid_y), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:37] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[1]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[2]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[3]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[4]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[5]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[6]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[7]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[8]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[9]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[10]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[11]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[12]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[13]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[14]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[15]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[16]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[17]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[18]\tTRAIN_DATA-rmse:0.27291\tVALID_DATA-rmse:0.25671\n",
      "[19]\tTRAIN_DATA-rmse:0.27198\tVALID_DATA-rmse:0.25579\n",
      "[20]\tTRAIN_DATA-rmse:0.27086\tVALID_DATA-rmse:0.25465\n",
      "[21]\tTRAIN_DATA-rmse:0.27086\tVALID_DATA-rmse:0.25465\n",
      "[22]\tTRAIN_DATA-rmse:0.27086\tVALID_DATA-rmse:0.25465\n",
      "[23]\tTRAIN_DATA-rmse:0.27086\tVALID_DATA-rmse:0.25465\n",
      "[24]\tTRAIN_DATA-rmse:0.27086\tVALID_DATA-rmse:0.25465\n",
      "[25]\tTRAIN_DATA-rmse:0.27086\tVALID_DATA-rmse:0.25465\n",
      "[26]\tTRAIN_DATA-rmse:0.27046\tVALID_DATA-rmse:0.25425\n",
      "[27]\tTRAIN_DATA-rmse:0.27046\tVALID_DATA-rmse:0.25425\n",
      "[28]\tTRAIN_DATA-rmse:0.27046\tVALID_DATA-rmse:0.25425\n",
      "[29]\tTRAIN_DATA-rmse:0.27046\tVALID_DATA-rmse:0.25425\n",
      "[30]\tTRAIN_DATA-rmse:0.27046\tVALID_DATA-rmse:0.25425\n",
      "[31]\tTRAIN_DATA-rmse:0.27008\tVALID_DATA-rmse:0.25387\n",
      "[32]\tTRAIN_DATA-rmse:0.27008\tVALID_DATA-rmse:0.25387\n",
      "[33]\tTRAIN_DATA-rmse:0.27008\tVALID_DATA-rmse:0.25387\n",
      "[34]\tTRAIN_DATA-rmse:0.27008\tVALID_DATA-rmse:0.25387\n",
      "[35]\tTRAIN_DATA-rmse:0.26957\tVALID_DATA-rmse:0.25334\n",
      "[36]\tTRAIN_DATA-rmse:0.26957\tVALID_DATA-rmse:0.25334\n",
      "[37]\tTRAIN_DATA-rmse:0.26957\tVALID_DATA-rmse:0.25334\n",
      "[38]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[39]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[40]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[41]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[42]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[43]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[44]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[45]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[46]\tTRAIN_DATA-rmse:0.26939\tVALID_DATA-rmse:0.25316\n",
      "[47]\tTRAIN_DATA-rmse:0.26874\tVALID_DATA-rmse:0.25250\n",
      "[48]\tTRAIN_DATA-rmse:0.26874\tVALID_DATA-rmse:0.25250\n",
      "[49]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[50]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[51]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[52]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[53]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[54]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[55]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[56]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[57]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[58]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[59]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[60]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[61]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[62]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[63]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[64]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[65]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[66]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[67]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[68]\tTRAIN_DATA-rmse:0.26788\tVALID_DATA-rmse:0.25164\n",
      "[69]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[70]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[71]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[72]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[73]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[74]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[75]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[76]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[77]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[78]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[79]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[80]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[81]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[82]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[83]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[84]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[85]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[86]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[87]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[88]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[89]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[90]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[91]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[92]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[93]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[94]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[95]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[96]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[97]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[98]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[99]\tTRAIN_DATA-rmse:0.26752\tVALID_DATA-rmse:0.25128\n",
      "[100]\tTRAIN_DATA-rmse:0.26732\tVALID_DATA-rmse:0.25108\n",
      "[101]\tTRAIN_DATA-rmse:0.26710\tVALID_DATA-rmse:0.25085\n",
      "[102]\tTRAIN_DATA-rmse:0.26710\tVALID_DATA-rmse:0.25085\n",
      "[103]\tTRAIN_DATA-rmse:0.26710\tVALID_DATA-rmse:0.25085\n",
      "[104]\tTRAIN_DATA-rmse:0.26710\tVALID_DATA-rmse:0.25085\n",
      "[105]\tTRAIN_DATA-rmse:0.26710\tVALID_DATA-rmse:0.25085\n",
      "[106]\tTRAIN_DATA-rmse:0.26710\tVALID_DATA-rmse:0.25085\n",
      "[107]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[108]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[109]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[110]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[111]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[112]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[113]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[114]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[115]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[116]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[117]\tTRAIN_DATA-rmse:0.26623\tVALID_DATA-rmse:0.24999\n",
      "[118]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[119]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[120]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[121]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[122]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[123]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[124]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[125]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[126]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[127]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[128]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[129]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[130]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[131]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[132]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[133]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[134]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[135]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[136]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[137]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[138]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[139]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[140]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[141]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[142]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[143]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[144]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[145]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[146]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[147]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[148]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[149]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[150]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[151]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[152]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[153]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[154]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[155]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[156]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[157]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "[158]\tTRAIN_DATA-rmse:0.26553\tVALID_DATA-rmse:0.24927\n",
      "ERROR:  0.062137780464753885\n"
     ]
    }
   ],
   "source": [
    "#TRAIN GRADIENT BOOSTED TREE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#Convert to Dmatrix\n",
    "TRAIN_DATA = xgb.DMatrix(train_x, train_y, feature_names = columns[1:15])\n",
    "VALID_DATA = xgb.DMatrix(valid_x, valid_y, feature_names = columns[1:15])\n",
    "#Parameters for boosted tree\n",
    "XGBOOST_PARAMS = {\"objective\": \"reg:squarederror\", \"subsample\": 0.6,\n",
    "                  \"colsample_bytree\" : 0.6, \"learning_rate\" : 0.1, \"max_depth\" : 100,\n",
    "                  \"alpha\": 20, \"n_estimators\": 12}\n",
    "#Train the xgboost model\n",
    "XGB_SLEEP_MODEL = xgb.train(XGBOOST_PARAMS, TRAIN_DATA, evals = [(TRAIN_DATA, \"TRAIN_DATA\"), (VALID_DATA, \"VALID_DATA\")],\n",
    "                            num_boost_round = 200, early_stopping_rounds = 40)\n",
    "predictions = XGB_SLEEP_MODEL.predict(VALID_DATA)\n",
    "error = mean_squared_error(valid_y, predictions)\n",
    "print('ERROR: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "XGB_SLEEP_MODEL.save_model('METRICS_SLEEP_GRADBOOSTED_MODELS[0.06].model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #Print desicion tree -> transparency into exactly what the model is doing\n",
    "ig, ax = plt.subplots(figsize=(30, 30))\n",
    "xgb.plot_tree(XGB_SLEEP_MODEL, num_trees=10, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb33c15c13a14f140d690812bf0a39a2e5e1e289641f45cea7a1bbeb79eff1a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
