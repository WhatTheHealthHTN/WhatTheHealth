{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv\n",
    "SLEEP_FITBIT_DATA = pd.read_csv(r'DATASETS\\SLEEP\\SLEEP_FITBIT_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLEEP_FITBIT_DATA.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of ideal values for each score; calculate L2 norm to generate score)\n",
    "IDEAL_VALS = {'HOURS_OF_SLEEP': 8, 'REM_SLEEP': 0.225, 'DEEP_SLEEP': 0.18, 'HEART_RATE_BELOW_RESTING': 0.58}\n",
    "columns = SLEEP_FITBIT_DATA.columns.values.tolist()\n",
    "columns = columns[:4]\n",
    "#Generate scores for each lever - compare iteratively and generate average score on its basis\n",
    "def generate_score(row):\n",
    "    #Iterate over each column except for gender\n",
    "    print(\" =================================== \")\n",
    "    total_score = 0\n",
    "    for column in columns:\n",
    "        if column == \"SCORE\": continue\n",
    "        print(row[column], IDEAL_VALS[column])\n",
    "        column_score = abs(row[column] - IDEAL_VALS[column])\n",
    "        print(column_score)\n",
    "        total_score += column_score\n",
    "    #Average out the score\n",
    "    row[\"SCORE\"] = total_score / len(columns)\n",
    "    print('END SCORE: ', row[\"SCORE\"])\n",
    "    return row\n",
    "\n",
    "SLEEP_FITBIT_DATA = SLEEP_FITBIT_DATA.apply(generate_score, axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SLEEP_FITBIT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SLEEP_FITBIT_DATA.head)\n",
    "SLEEP_FITBIT_DATA.to_pickle('PREPROCESSED_SLEEP_FITBIT_DATA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape tensors for XGBOOST\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_features = SLEEP_FITBIT_DATA.iloc[:, :3]\n",
    "print(x_features)\n",
    "y_labels = SLEEP_FITBIT_DATA[\"SCORE\"]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x_features, y_labels, random_state = 2, shuffle = True)\n",
    "\n",
    "train_x = tf.convert_to_tensor(train_x)\n",
    "train_x = tf.reshape(train_x, [len(train_x), 3])\n",
    "\n",
    "valid_x = tf.convert_to_tensor(valid_x)\n",
    "valid_x = tf.reshape(valid_x, [len(valid_x), 3])\n",
    "\n",
    "train_y = tf.convert_to_tensor(train_y)\n",
    "train_y = tf.reshape(train_y, [len(train_y), 1])\n",
    "\n",
    "valid_y = tf.convert_to_tensor(valid_y)\n",
    "valid_y = tf.reshape(valid_y, [len(valid_y), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN GRADIENT BOOSTED TREE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#Convert to Dmatrix\n",
    "TRAIN_DATA = xgb.DMatrix(train_x, train_y, feature_names = columns[1:15])\n",
    "VALID_DATA = xgb.DMatrix(valid_x, valid_y, feature_names = columns[1:15])\n",
    "#Parameters for boosted tree\n",
    "XGBOOST_PARAMS = {\"objective\": \"reg:squarederror\", \"subsample\": 0.6,\n",
    "                  \"colsample_bytree\" : 0.6, \"learning_rate\" : 0.1, \"max_depth\" : 100,\n",
    "                  \"alpha\": 20, \"n_estimators\": 12}\n",
    "#Train the xgboost model\n",
    "XGB_SLEEP_MODEL = xgb.train(XGBOOST_PARAMS, TRAIN_DATA, evals = [(TRAIN_DATA, \"TRAIN_DATA\"), (VALID_DATA, \"VALID_DATA\")],\n",
    "                            num_boost_round = 200, early_stopping_rounds = 40)\n",
    "predictions = XGB_SLEEP_MODEL.predict(VALID_DATA)\n",
    "error = mean_squared_error(valid_y, predictions)\n",
    "print('ERROR: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model\n",
    "XGB_SLEEP_MODEL.save_model('METRICS_SLEEP_GRADBOOSTED_MODELS[0.06].model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print desicion tree -> transparency into exactly what the model is doing\n",
    "ig, ax = plt.subplots(figsize=(30, 30))\n",
    "xgb.plot_tree(XGB_SLEEP_MODEL, num_trees=10, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
